from datetime import datetime
from fastapi import APIRouter, HTTPException, Body
from pydantic import BaseModel
from typing import List, Optional, Dict, Any

from ..ai.llm import LLM
from ..dataVendors import functionTool


chatRouter = APIRouter()
llm = LLM()


class DataVendor(BaseModel):
    name: str
    api_key: Optional[str] = None


class Message(BaseModel):
    role: str
    content: str


class ChatRequest(BaseModel):
    messages: List[Message]
    data_vendor: DataVendor


class ToolCall(BaseModel):
    name: str
    arguments: Dict[str, Any]


class ToolSelectionResponse(BaseModel):
    tools: List[ToolCall]


class ChatResponse(BaseModel):
    response: str


@chatRouter.post("/tool", response_model=ToolSelectionResponse)
async def select_tools(chat_request: ChatRequest):
    """
    Endpoint to determine the necessary tools and their parameters for a given user query.
    """
    try:
        user_query = chat_request.messages[-1].content
        tool_calls = llm.select_tools(user_query)
        print(f"tool calls : {tool_calls}")

        tools_to_return = [
            ToolCall(name=tool["name"], arguments=tool["arguments"])
            for tool in tool_calls
        ]
        return ToolSelectionResponse(tools=tools_to_return)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error: {e}")


@chatRouter.post("/", response_model=ChatResponse)
async def chat(
    chat_request: ChatRequest,
    tool_calls: List[Dict[str, Any]] = Body(None, embed=True),
):
    """
    Main chat endpoint.  Handles both initial tool selection (if tool_calls is not provided)
    and final response generation (if tool_calls is provided).
    """
    try:
        user_query = chat_request.messages[-1].content
        data_vendor_name = chat_request.data_vendor.name
        data_vendor_api_key = chat_request.data_vendor.api_key

        # these should be a while loop that will yield response until the response is completed
        # call the appropriate function based on the tool calls if tool_calls is provided
        # if tool_calls is not provided, select the tools based on the user query using llm
        # call functions based on the tool calls generated by llm
        # call llm with tool responses to generate answer

        # chat_request.messages.extend(
        #     {
        #         "role": "system",
        #         "content": f"Today is {datetime.today().strftime('%Y-%m-%d')}",
        #     }
        # )
        if tool_calls is None:
            tool_calls = llm.select_tools(user_query)

        functionResult = []
        for tool_call in tool_calls:
            print(f"tool_call : {tool_call}")
            function_name = tool_call["tool_name"]
            function_args = tool_call["parameters"]
            function_args["data_vendor"] = data_vendor_name
            function_args["api_key"] = data_vendor_api_key
            if hasattr(functionTool, function_name):
                function_call = getattr(functionTool, function_name)
                function_result = function_call(**function_args)
                functionResult.append(
                    {
                        "role": "system",
                        "content": str(
                            {
                                "function_name": function_name,
                                "function_result": function_result,
                            }
                        ),
                    }
                )

        chat_request.messages.extend([Message(role="user", content=user_query)])
        chat_request.messages.extend(functionResult)

        response = llm.chatCompletion(
            model="qwen-2.5-32b",
            messages=chat_request.messages,
        )
        print(f"response : {response}")
        return ChatResponse(response=response.choices[0].message.content)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error: {e}")
